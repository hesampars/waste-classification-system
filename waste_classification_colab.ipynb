{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOOiGEbs6wLv"
      },
      "source": [
        "# Waste Classification System - Google Colab Setup\n",
        "\n",
        "This notebook will guide you through setting up and running the waste classification system in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Beqg_iU6wLy"
      },
      "source": [
        "## 1. Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgHJQaU46wLy"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision timm numpy pillow opencv-python matplotlib scikit-learn tqdm requests gradio ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKbT4v9t6wLz"
      },
      "source": [
        "## 2. Clone the Repository\n",
        "\n",
        "Make sure you've created your GitHub repository and uploaded the project files as instructed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0-Jxv_b6wL0"
      },
      "outputs": [],
      "source": [
        "# Clone your repository (replace with your actual repository URL)\n",
        "!git clone https://github.com/yourusername/waste-classification-system.git\n",
        "%cd waste-classification-system\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p data models output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Gsl4jy6wL0"
      },
      "source": [
        "## 3. Mount Google Drive\n",
        "\n",
        "We'll mount your Google Drive to access the dataset zip files you've manually downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3OOVsy6wL1"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R8iKGyT6wL1"
      },
      "source": [
        "## 4. Upload Datasets to Google Drive\n",
        "\n",
        "Before running the next cell, make sure you've:\n",
        "1. Created a folder in your Google Drive (e.g., 'waste_datasets')\n",
        "2. Uploaded your dataset zip files to this folder:\n",
        "   - MJU-Waste.zip\n",
        "   - TACO-master.zip\n",
        "   - trashnet-master.zip\n",
        "   - waste-pictures.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxRGX9Q16wL2"
      },
      "outputs": [],
      "source": [
        "# Create a directory for the datasets\n",
        "!mkdir -p data\n",
        "\n",
        "# Copy datasets from Google Drive to the project\n",
        "# Adjust the path if your folder structure is different\n",
        "!cp /content/drive/MyDrive/waste_datasets/*.zip data/\n",
        "\n",
        "# List the copied files\n",
        "!ls -la data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2PgU5v6wL2"
      },
      "source": [
        "## 5. Extract and Process Datasets\n",
        "\n",
        "Now we'll extract the datasets and prepare them for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LB7T47A6wL3"
      },
      "outputs": [],
      "source": [
        "# Extract datasets using our download script\n",
        "# The --skip-existing flag tells it to use the zip files we've already uploaded\n",
        "!python scripts/download_datasets.py --skip-existing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIBrNdgA6wL3"
      },
      "outputs": [],
      "source": [
        "# Download Open Images dataset (this may take some time)\n",
        "# Uncomment if you want to download Open Images\n",
        "# !python scripts/download_datasets.py --datasets open-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf5Irx236wL4"
      },
      "outputs": [],
      "source": [
        "# Preprocess all datasets\n",
        "!python scripts/preprocess_datasets.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xMKUOG46wL4"
      },
      "source": [
        "## 6. Train Models\n",
        "\n",
        "Now we can train our classification models. You can choose to train individual models or all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzBvlukc6wL4"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztn-20xJ6wL5"
      },
      "outputs": [],
      "source": [
        "# Train ConvNeXt Large model\n",
        "# Uncomment to run\n",
        "# !python scripts/train.py --model convnext_large --epochs 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7tSIQ3e6wL5"
      },
      "outputs": [],
      "source": [
        "# Train EfficientNetV2-L model\n",
        "# Uncomment to run\n",
        "# !python scripts/train.py --model tf_efficientnetv2_l --epochs 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh2V5j0i6wL6"
      },
      "outputs": [],
      "source": [
        "# Train Swin Transformer Large model\n",
        "# Uncomment to run\n",
        "# !python scripts/train.py --model swin_large_patch4_window7_224 --epochs 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-I3-VSI6wL6"
      },
      "outputs": [],
      "source": [
        "# Train all models (this will take a long time)\n",
        "# Uncomment to run\n",
        "# !python scripts/train.py --model all --epochs 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfdAJ12t6wL6"
      },
      "source": [
        "## 7. Save Trained Models to Google Drive\n",
        "\n",
        "After training, we should save the models to Google Drive so they're not lost when the Colab session ends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG24pIEO6wL6"
      },
      "outputs": [],
      "source": [
        "# Create a directory in Google Drive for the models\n",
        "!mkdir -p /content/drive/MyDrive/waste_classification_models\n",
        "\n",
        "# Copy the trained models to Google Drive\n",
        "!cp -r models/* /content/drive/MyDrive/waste_classification_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv5qe2km6wL7"
      },
      "source": [
        "## 8. Run the Application\n",
        "\n",
        "Finally, we can run the application with Gradio interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9WXXZKN6wL7"
      },
      "outputs": [],
      "source": [
        "# Run the application\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}